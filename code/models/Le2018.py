import numpy as np
import time
import json
import tensorflow as tf
from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras import regularizers
from keras import backend as K
import sklearn.metrics as metrics

from .Basics import MachineLearningModel

class CNN(MachineLearningModel):
    """
        This class is based on Le2018 work.
    """

    def __init__(
        self,
        path,
        ext='exe',
        max_len=1e4,
        use_lstm=True,
        use_lstm_bidirectional=True,
        max_epochs=250,
        patience=10,
        batch_size=64
    ):
        """
        Parameters
        ----------
        path : str
            Path to malware dataset
        max_len : int
            Length of the 1D malware data (default 1e4)
        use_lstm : int
            Flag to use cnn-lstm model if True or cnn if False (default True)
        max_epochs : int
            Number of max epochs to be run (default 250)
        patience : int
            Early stopping criteria. If improvement is not made for <patience> epochs (default 10) training stops
        batch_size : int
            Batch size (default 64)
        """

        self.max_len     = int(max_len)
        self.max_epochs  = max_epochs
        self.batch_size  = batch_size
        self.use_lstm    = use_lstm
        self.bidirectional    = use_lstm_bidirectional
        self.patience    = patience
        self.model       = None
        self.best_epoch  = -1

        # Init parent class
        MachineLearningModel.__init__(self,
                                      path,
                                      'model_original_le2018_',
                                      ext=ext,
                                      batch_size=self.batch_size)

        # Uncomment this block to train the model on GPU
        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.7)
        config = tf.compat.v1.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True, log_device_placement=True, device_count={'GPU': 1})
        session = tf.compat.v1.Session(config=config)
        tf.compat.v1.keras.backend.set_session(session)

    def train(self,
              n_folds=1,
              split_method='nataraj',
              use_subset=False,
              test_npz=None,
              binarize=False,
              augmenters=None):
        self.logger.info("** Training started!")

        # Set augmentation methods to be used
        self.augmenters = augmenters

        self.data_handler.split_dataset(n_folds=n_folds,
                                        split_method=split_method,
                                        use_subset=use_subset)
        self.n_classes = self.data_handler.n_classes

        self.logger.info("** Fitting {} classes!".format(self.n_classes))

        avg_acc  = []
        avg_f1   = []
        avg_time = []
        test_acc = 0


        inj_avg_acc  = []
        inj_avg_f1   = []
        inj_avg_time = []

        for fold in range(n_folds):
            self.logger.info("===== FOLD {} =====".format(fold))

            self.data_handler.compute_fold_split()

            if self.use_lstm:
                self.model = self.create_cnn_lstm_model(
                    n_class=self.data_handler.n_classes,
                    bidirectional=self.bidirectional
                )
            else:
                self.model = self.create_cnn_model(
                    n_class=self.data_handler.n_classes
                )

            print(self.model.summary())

            # Run training in fold
            train_time = self._train(fold)
            fold_model = self.get_tmp_model_path() + str(self.best_epoch) + '_f' + str(fold) + '.h5'
            self.model_paths.append(fold_model)

            # Test with unseen data
            test_data = self.data_handler.get_test_data()
            test_acc, test_f1, test_time  = self._test(fold+1,
                                                       fold_model,
                                                       test_data)
            self.results[fold+1] = {
                "acc": test_acc,
                "f1": test_f1,
                "train_time": train_time,
                "test_time": test_time
            }
            total_time = train_time + test_time
            avg_acc.append(test_acc)
            avg_f1.append(test_f1)
            avg_time.append(total_time)

            for npz in test_npz:
                # Test with injected data
                test_acc, test_f1, test_time  = self._test_injected(npz,
                                                                    fold+1,
                                                                    fold_model,
                                                                    binarize=None)
                self.results[f"{fold+1}_injected"] = {
                    "path": npz,
                    "acc": test_acc,
                    "f1": test_f1,
                    "test_time": test_time
                }
                inj_avg_acc.append(test_acc)
                inj_avg_f1.append(test_f1)
                inj_avg_time.append(test_time)
        print_str = "** Finished training in {}s! Average ACC: {}; STD DEV {};".format(
                        np.mean(avg_time),
                        np.mean(avg_acc),
                        np.std(avg_acc)
                    )
        self.logger.warning(print_str)
        self.data_handler.save_to_log(print_str  + '\n')
        self.data_handler.save_to_log(json.dumps(self.results))

    def _train(self, fold, epoch_range_start=0):

        train_data = self.data_handler.get_train_data()
        training_set_size = len(train_data)
        n_batches = np.ceil(training_set_size/self.batch_size)

        # Used to get the epoch with best results and load its model for testing
        best_acc = 0
        best_loss = 999999
        distance_from_improvement = 0

        total_time = 0

        # Run epochs
        for epoch in range(epoch_range_start, self.max_epochs):
            self.logger.info(
                "Epoch {}: training on {} samples.".format(
                    epoch+1,
                    training_set_size
                )
            )

            # Mini-batch gradient descent
            np.random.shuffle(train_data)
            train_acc = 0
            train_loss = 0

            start = time.time()

            for idx in range(0, training_set_size, self.batch_size):

                batch_X, batch_y = self.data_handler.load_raw_exe(
                    train_data[idx:idx+self.batch_size],
                    height=1,
                    width=self.max_len,
                    categorical_y=True,
                    augmenters=self.augmenters
                )

                self.logger.info(
                    "Data info --> train: {} : {}".format(
                        batch_X.shape,
                        batch_y.shape,
                    )
                )


                ret = self.model.train_on_batch(
                    batch_X,
                    batch_y,
                )

                train_loss += ret[0]
                train_acc  += ret[1]

            end = time.time()

            time_diff = int(end - start)
            total_time += time_diff

            # Call validation method
            validation_acc, validation_loss = self._validate()

            ############################
            #######    DEBUG    ########
            ############################

            self.logger.info(
                "*TRAINING* SET => ACC: {:.4f} ; " \
                "LOSS: {:.4f}"
                .format(
                    train_acc/n_batches,
                    train_loss/n_batches
                )
            )

            self.logger.info(
                "*VALIDATE* SET => ACC: {:.4f} ; " \
                "LOSS: {:.4f}"
                .format(
                    validation_acc,
                    validation_loss
                )
            )

            self.logger.info(
                "Finished epoch in {}s.".format(time_diff)
            )

            self.data_handler.save_to_log(
                "epoch: {}, train_acc: {}, train_loss: {}, valid_acc: {}, valid_los: {}, time: {}s\n"
                .format(
                    (epoch+1),
                    train_acc/n_batches,
                    train_loss/n_batches,
                    validation_acc,
                    validation_loss,
                    time_diff
                )
            )

            ###############################
            ###      EARLY STOPPING     ###
            ###############################

            # Save epoch with best validation loss for testing
            if validation_acc > best_acc:
                best_loss                 = validation_loss
                best_acc                  = validation_acc
                self.best_epoch           = (epoch+1)
                distance_from_improvement = 0

                # Save network parameters
                self.model.save_weights(
                    self.get_tmp_model_path() + str(epoch+1) + '_f' + str(fold) + '.h5'
                )
            else:
                distance_from_improvement += 1

            if distance_from_improvement > self.patience:

                print_str = "***** No improvement in last {} epochs! "\
                "Stopping. Best epoch: {} => ACC: {}; LOSS: {};" \
                .format(
                    self.patience,
                    self.best_epoch,
                    best_acc,
                    best_loss,
                )
                self.logger.warning(print_str)
                self.data_handler.save_to_log(print_str + '\n')
                break

        return total_time

    def _validate(self):

        validation_acc = 0
        validation_loss = 0
        validation_data = self.data_handler.get_validation_data()
        validation_set_size = len(validation_data)
        n_batches = np.ceil(validation_set_size/self.batch_size)

        self.logger.info(
            "[*] Running validation on {} samples.".format(
                validation_set_size,
            )
        )

        for idx in range(0, validation_set_size, self.batch_size):

            validation_X, validation_y = self.data_handler.load_raw_exe(
                validation_data[idx:idx+self.batch_size],
                height=1,
                width=self.max_len,
                categorical_y=True
            )

            self.logger.info(
                "Data info --> validation: {} : {}".format(
                    validation_X.shape,
                    validation_y.shape,
                )
            )

            ret = self.model.test_on_batch(
                validation_X,
                validation_y
            )

            validation_loss += ret[0]
            validation_acc  += ret[1]

        return validation_acc/n_batches, validation_loss/n_batches

    def _test(self, fold, model_path, test_data):

        self.logger.warning("*** Loading tensorflow Graph from {}.".format(model_path))

        result_file = self.data_handler.create_file(
            name="test_results_{}.txt".format(fold),
        )

        test_set_size = len(test_data)
        labels = []
        predictions = []
        scores = []

        self.model.load_weights(model_path)

        start_test_predict = time.time()

        for idx in range(0, test_set_size, self.batch_size):

            samples = test_data[idx:idx+self.batch_size]

            test_X, test_y = self.data_handler.load_raw_exe(
                samples,
                height=1,
                width=self.max_len,
                categorical_y=False
            )

            y_predict = self.model.predict(test_X)

            for i in range(len(test_y)):
                predicted_class = np.argmax(y_predict[i])

                labels.append(test_y[i])
                predictions.append(predicted_class)
                scores.append(y_predict[i])

                result_file.write("{}, {}\n".format(test_y[i],
                                                    predicted_class))

        end_test_predict = time.time()

        acc = metrics.accuracy_score(labels, predictions)
        f1 = metrics.f1_score(labels, predictions, average="weighted")

        difference = int(end_test_predict - start_test_predict)

        print_str = "\t\t *TEST* SET => Time: {}s; ACC: {:.4f}; F1: {:.4f}".format(difference, acc, f1)

        self.logger.info(print_str)
        result_file.write(print_str)

        self.logger.info(f" Saving npz: metrics_test_results_{fold}.npz")
        np.savez(f"{self.data_handler.tmp_output_path}/metrics_test_results_{fold}.npz",
            y_true=labels,
            y=predictions,
            p=scores,
            acc=acc,
            f1=f1)

        self.logger.info("** Testing finished!")

        return acc, f1, difference

    def test(self, path):
        self.logger.info("[*] Running in test only mode.")

        self.data_handler.split_dataset()
        self.n_classes = self.data_handler.n_classes
        self.data_handler.compute_fold_split()

        self.logger.info("** Fitting {} classes!".format(self.n_classes))

        if self.use_lstm:
            self.model = self.create_cnn_lstm_model(
                n_class=self.data_handler.n_classes,
                bidirectional=self.bidirectional
            )
        else:
            self.model = self.create_cnn_model(
                n_class=self.data_handler.n_classes
            )

        self._test('test_only', path, self.data_handler.get_all_data())

    def test_injected(self, base_path, subdir, sections=5, bytes=5, bytes_start=1, bytes_increment=1):
        result_json = {}

        for _model in self.model_paths:
            self.logger.info("[@@] Evaluating {} _model".format(_model))
            for _section in range(1, sections+1):
                for _byte in range(bytes_start, bytes+1, bytes_increment):
                    dataset_path = "{}_{}_{}/{}/".format(base_path, _section, _byte, subdir)
                    _split       = "{}_{}".format(_section, _byte)

                    from .Data import MalImgDataset
                    _data_handler = MalImgDataset(dataset_path,
                                                  extension=self.ext,
                                                  batch_size=self.batch_size,
                                                  output_mode=False)
                    _data_handler.split_dataset()
                    _data_handler.compute_fold_split()

                    test_acc = self._test("injected_{}".format(_split),
                                          _model,
                                          _data_handler.get_all_data())
                    if _split not in result_json.keys():
                        result_json[_split] = [ test_acc ]
                    else:
                        result_json[_split].append(test_acc)
        result_file = self.data_handler.create_file(name="injected_results.txt")

        final_result = {
            "regular_tests" : self.results,
            "injection_tests" : result_json
        }
        result_file.write(json.dumps(final_result))

        return final_result

    def _test_injected(self, npz, fold, model_path, binarize=None):

        data = np.load(npz, mmap_mode='r', allow_pickle=True)

        total_samples = data['y'].shape[0]
        MBS=4096

        self.logger.warning("*** Loading tensorflow Graph from {}. Testing against {} samples.".format(model_path, total_samples))

        result_file_name = "{}_{}".format(npz.split('/')[-1].split('.')[0], fold)
        result_file = self.data_handler.create_file(
            name=f"test_results_{result_file_name}.txt",
        )

        labels = []
        predictions = []
        scores = []

        self.model.load_weights(model_path)

        # https://stackoverflow.com/questions/59216547/python-npzfile-objects-are-very-slow
        m_X = data['X']
        m_y = data['y']

        start_test_predict = time.time()

        for idx in range(0, total_samples, MBS):

            batchX = m_X[idx:idx+MBS]
            batchY = m_y[idx:idx+MBS]
            size = batchX.shape[0]

            batch_data = list(zip(batchX, batchY))

            # Select a random negative as source for data injection
            # negative_sample = negative_paths[random.randint(0, negative_set_size-1)]

            X, _ = self.data_handler.load_raw_exe(
                batch_data,
                height=1,
                width=self.max_len,
                categorical_y=False,
                from_data=True
            )

            probs = self.model.predict(X)

            for _id in range(size):

                # if binarize in [None, False]:
                y = batchY[_id]
                # else:
                #     y = 1 if batchY[_id] == binarize else 0

                # X = self.data_handler.buffer_to_image(batchX[_id], 1, self.max_len)

                # # print(batchX[_id].shape, X.shape)

                # _y = self.model.predict(np.array([X]))
                # score = _y[0][1] # probability of being malware
                score = probs[_id]
                _y = np.argmax(score)

                scores.append(score)
                labels.append(int(y))
                predictions.append(_y)

                result_file.write("{}, {}\n".format(y,
                                                    _y))

        end_test_predict = time.time()

        acc = metrics.accuracy_score(labels, predictions)
        f1 = metrics.f1_score(labels, predictions, average="weighted")
        # precision, recall, thresholds = metrics.precision_recall_curve(labels, scores)

        difference = int(end_test_predict - start_test_predict)

        print_str = "\t\t *TEST* SET (INJECTED) => Time: {}s; ACC: {:.4f}; F1: {:.4f}".format(difference, acc, f1)

        self.logger.info(print_str)
        result_file.write(print_str)


        self.logger.info(f" Saving npz: {result_file_name}.npz")
        np.savez(f"{self.data_handler.tmp_output_path}/metrics_{result_file_name}.npz",
                 y_true=labels,
                 y=predictions,
                 p=scores,
                 acc=acc,
                 f1=f1)
                #  precision=precision,
                #  recall=recall,
                #  thresholds=thresholds)

        self.logger.info("** Injection Testing finished!")

        return acc, f1, difference

    def test_online_injection(self):

        import random

        self.logger.warning("[@@@@@@@] Starting ONLINE INJECTION TEST.")

        fold = 1
        for _model in self.model_paths:

            self.logger.warning("*** Loading tensorflow Graph from {}.".format(_model))
            self.model.load_weights(_model)

            for _class in self.data_handler.class_map.keys():

                if _class == 'benign':
                    continue

                _id = self.data_handler.class_map[_class]

                self.logger.warning("\t[&] Testing injection on {} samples.".format(_class))

                result_file = self.data_handler.create_file(
                    name="test_results_online_injection_{}_{}.txt".format(_class, fold),
                )

                test_data = np.array(self.data_handler.get_test_data())
                test_set_size = test_data.shape[0]

                labels = []
                predictions = []

                # Split paths into positive and negative samples (one against all)
                positive_paths = test_data[np.where(test_data[:, 1] == str(_id))][:,0]
                negative_paths = test_data[np.where(test_data[:, 1] != str(_id))][:,0]

                negative_set_size = negative_paths.shape[0]

                start_test_predict = time.time()

                for _positive in positive_paths:
                    # Select a random negative as source for data injection
                    negative_sample = negative_paths[random.randint(0, negative_set_size-1)]

                    # self.logger.info("Injecting at {} from {}.".format(_positive, negative_sample))

                    # Inject section into the negative
                    test_X = self.data_handler.inject_from_file(_positive,
                                                                None,
                                                                n_injected_sections=5,
                                                                n_bytes=5,
                                                                height=1,
                                                                width=self.max_len)

                    _X, _ = self.data_handler.load_raw_exe(
                        [(_positive, _id)],
                        height=1,
                        width=self.max_len,
                        categorical_y=False
                    )
                    _y_original = self.model.predict(_X)

                    # print(f"[ON] {_X.shape} | {test_X.shape}")

                    # Perform prediction
                    y_predict = self.model.predict(np.array([test_X]))


                    predicted_class = np.argmax(y_predict[0])

                    labels.append(_id)
                    predictions.append(predicted_class)

                    result_file.write(f"{_positive} => orig: {_y_original} | inject: {y_predict}")
                    result_file.write("[{}]: {}, {}\n".format(_class, _id,
                                                        predicted_class))

                end_test_predict = time.time()

                # Compute time
                difference = int(end_test_predict - start_test_predict)

                # Compute metrics
                acc = metrics.accuracy_score(labels, predictions)
                f1 = metrics.f1_score(labels, predictions, average="weighted")

                print_str = "\t\t *TEST* SET => Time: {}s; ACC: {:.4f}; F1: {:.4f}".format(difference, acc, f1)

                self.logger.info(print_str)
                result_file.write(print_str)

                self.logger.info("** Testing finished!")

            fold += 1


    def create_cnn_lstm_model(self, n_class, bidirectional=True):
        """
        generate CNN with 1 or Bi directional LSTM on top
        Parameters:
            n_class: number of classes
            bidirectional: boolean value: to generate uni or bidirectional LSTM on top of CNN layers
        Return:
            the CNN -UniLSTM or CNN-BiLSTM model
        """
        cnn_lstm_model = models.Sequential()

        cnn_lstm_model.add(layers.Conv1D(filters=30, kernel_size=7, strides=1, kernel_regularizer=regularizers.l2(0.01), activation='relu', input_shape=(self.max_len, 1)))
        cnn_lstm_model.add(layers.MaxPool1D(5))
        cnn_lstm_model.add(layers.Conv1D(filters=50, kernel_size=7, strides=1, kernel_regularizer=regularizers.l2(0.01), activation='relu'))
        cnn_lstm_model.add(layers.MaxPool1D(5))
        cnn_lstm_model.add(layers.Conv1D(filters=90, kernel_size=7, strides=1, kernel_regularizer=regularizers.l2(0.01), activation='relu'))
        cnn_lstm_model.add(layers.MaxPool1D(5))

        if bidirectional:
            cnn_lstm_model.add(layers.Bidirectional(layers.LSTM(units=128, dropout=0.2, recurrent_dropout=0.2)))
        else:
            cnn_lstm_model.add(layers.LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))

        cnn_lstm_model.add(layers.Dense(n_class, activation='softmax'))

        cnn_lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

        return cnn_lstm_model

    def create_cnn_model(self, n_class):
        """
        generate the CNN model
        Parameters:
            n_class: number of classes
        Return:
            the CNN model
        """
        cnn_model_ = models.Sequential()

        cnn_model_.add(layers.Conv1D(filters=30, kernel_size=7, strides=1, kernel_regularizer=regularizers.l2(0.01), activation='relu', input_shape=(self.max_len, 1)))
        cnn_model_.add(layers.MaxPool1D(5))
        cnn_model_.add(layers.Conv1D(filters=50, kernel_size=7, strides=1, kernel_regularizer=regularizers.l2(0.01), activation='relu'))
        cnn_model_.add(layers.MaxPool1D(5))
        cnn_model_.add(layers.Conv1D(filters=90, kernel_size=7, strides=1, kernel_regularizer=regularizers.l2(0.01), activation='relu'))
        cnn_model_.add(layers.MaxPool1D(5))

        cnn_model_.add(layers.Flatten())
        cnn_model_.add(layers.Dropout(0.2))
        cnn_model_.add(layers.Dense(256, activation='relu'))
        cnn_model_.add(layers.Dropout(0.3))
        cnn_model_.add(layers.Dense(n_class, activation='softmax'))

        cnn_model_.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

        return cnn_model_
