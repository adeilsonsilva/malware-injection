import cv2
import numpy as np
import time
import json
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import sklearn.metrics as metrics
from sklearn.preprocessing import label_binarize
import multiprocessing as mp
from functools import partial

from .Basics import MachineLearningModel

# 1MB = 2**20 == 1048576
# 2MB = 2**21 == 2097152

class Net(nn.Module):
  # trained to minimize cross-entropy loss
  # criterion = nn.CrossEntropyLoss()
  def __init__(self, out_size=2, channels=128, window_size=512, embd_size=8):
    super(Net, self).__init__()
    self.embd = nn.Embedding(257, embd_size, padding_idx=0)

    self.window_size = window_size

    self.conv_1 = nn.Conv1d(embd_size, channels, window_size, stride=window_size, bias=True)
    self.conv_2 = nn.Conv1d(embd_size, channels, window_size, stride=window_size, bias=True)

    self.pooling = nn.AdaptiveMaxPool1d(1)

    self.fc_1 = nn.Linear(channels, channels)
    self.fc_2 = nn.Linear(channels, out_size)

  def forward(self, x):

    x = self.embd(x.long())
    x = torch.transpose(x,-1,-2)

    cnn_value = self.conv_1(x)
    gating_weight = torch.sigmoid(self.conv_2(x))

    x = cnn_value * gating_weight

    x = self.pooling(x)

    #Flatten
    x = x.view(x.size(0), -1)

    x = F.relu(self.fc_1(x))
    x = self.fc_2(x)

    return x

class Malconv(MachineLearningModel):
  """
      This class is a new implementation of Maups idea.
  """

  def __init__(
    self,
    path,
    ext='exe',
    max_len=2**21,
    max_epochs=10,
    patience=3,
    batch_size=512,
    binarize=None
  ):
    """
    Parameters
    ----------
    path : str
        Path to malware dataset
    max_len : int
        Length of the 1D malware data (default 2**21 [2MB])
    max_epochs : int
        Number of max epochs to be run (default 250)
    patience : int
        Early stopping criteria. If improvement is not made for <patience> epochs (default 10) training stops
    batch_size : int
        Batch size (default 64)
    """

    self.max_len     = int(max_len)
    self.max_epochs  = max_epochs
    self.batch_size  = batch_size
    self.patience    = patience
    self.model       = None
    self.best_epoch  = -1
    self.augmenter   = None

    # Init parent class
    MachineLearningModel.__init__(self,
                                  path,
                                  'model_raff2017_',
                                  ext=ext,
                                  batch_size=self.batch_size)

    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.enabled = True

  def train(self,
            n_folds=1,
            split_method='nataraj',
            use_subset=False,
            binarize=None,
            test_npz=None,
            augmenters=None):
    self.logger.info("** Training started!")

    # Set augmentation methods to be used
    self.augmenters = augmenters

    self.data_handler.split_dataset(n_folds=n_folds,
                                    split_method=split_method,
                                    use_subset=use_subset,
                                    binarize_dataset=binarize)
    self.n_classes = self.data_handler.n_classes

    self.logger.info("** Fitting {} classes!".format(self.n_classes))

    avg_acc  = []
    avg_f1   = []
    avg_time = []

    inj_avg_acc  = []
    inj_avg_f1   = []
    inj_avg_time = []

    for fold in range(n_folds):
      self.logger.info("===== FOLD {} =====".format(fold))

      self.data_handler.compute_fold_split()

      self.model = Net(out_size=self.data_handler.n_classes).cuda()
      self.optimizer = optim.SGD(self.model.parameters(),
                                 lr=1e-2,
                                 momentum=0.9,
                                 nesterov=True,
                                 weight_decay=1e-3)
      print(self.model)

      # Run training in fold
      train_time = self._train(fold)
      fold_model = self.get_tmp_model_path() + str(self.best_epoch) + '_f' + str(fold) + '.pt'
      self.model_paths.append(fold_model)

      # Test with unseen data
      test_data = self.data_handler.get_test_data()
      test_acc, test_f1, test_time  = self._test(fold+1,
                                                 fold_model,
                                                 test_data)
      self.results[fold+1] = {
        "acc": test_acc,
        "f1": test_f1,
        "train_time": train_time,
        "test_time": test_time
      }
      total_time = train_time + test_time
      avg_acc.append(test_acc)
      avg_f1.append(test_f1)
      avg_time.append(total_time)

      for npz in test_npz:
          # Test with injected data
          test_acc, test_f1, test_time  = self._test_injected(npz,
                                                              fold+1,
                                                              fold_model,
                                                              binarize=binarize)
          self.results[f"{fold+1}_injected"] = {
              "path": npz,
              "acc": test_acc,
              "f1": test_f1,
              "test_time": test_time
          }
          inj_avg_acc.append(test_acc)
          inj_avg_f1.append(test_f1)
          inj_avg_time.append(test_time)
    print_str = "** Finished training in {}s! Average ACC: {}; STD DEV {};".format(
      np.mean(avg_time),
      np.mean(avg_acc),
      np.std(avg_acc)
    )
    self.logger.warning(print_str)
    self.data_handler.save_to_log(print_str  + '\n')
    self.data_handler.save_to_log(json.dumps(self.results))

  def _train(self, fold, epoch_range_start=0):

    train_data = self.data_handler.get_train_data()
    training_set_size = len(train_data)
    n_batches = np.ceil(training_set_size/self.batch_size)

    # Used to get the epoch with best results and load its model for testing
    best_acc = 0
    best_loss = 999999
    distance_from_improvement = 0

    # Run epochs
    for epoch in range(epoch_range_start, self.max_epochs):
      self.logger.info(
        "Epoch {}: training on {} samples.".format(
          epoch+1,
          training_set_size
        )
      )

      # Mini-batch gradient descent
      np.random.shuffle(train_data)
      train_acc = 0
      train_loss = 0

      start = time.time()

      for idx in range(0, training_set_size, self.batch_size):

        batch_X, batch_y = self.data_handler.load_sequence(
          train_data[idx:idx+self.batch_size],
          length=self.max_len,
          augmenters=self.augmenters
        )

        X = torch.from_numpy(batch_X).cuda()
        y = torch.from_numpy(batch_y).long().cuda() # cross_entropy expect long for target

        self.model.train()
        _y = self.model(X).cuda()

        # print(X)
        # print(_y)

        # self.logger.info(
        #   "Data info --> train: {} : {} x {}".format(
        #     X.shape,
        #     y.shape,
        #     _y.shape,
        #   )
        # )

        # Run backward propagation
        self.optimizer.zero_grad()
        loss = F.cross_entropy(_y, y)
        loss.backward()
        self.optimizer.step()

        # print(torch.argmax(_y, dim=1))

        _acc = ((torch.argmax(_y, dim=1)  == y).sum().item() / X.shape[0])

        train_loss += loss.item()
        train_acc  += _acc

      end = time.time()

      time_diff = int(end - start)

      # Call validation method
      validation_acc, validation_loss = self._validate()

      ############################
      #######    DEBUG    ########
      ############################

      self.logger.info(
        "*TRAINING* SET => ACC: {:.4f} ; " \
        "LOSS: {:.4f}"
        .format(
          train_acc/n_batches,
          train_loss/n_batches
        )
      )

      self.logger.info(
        "*VALIDATE* SET => ACC: {:.4f} ; " \
        "LOSS: {:.4f}"
        .format(
          validation_acc,
          validation_loss
        )
      )

      self.logger.info(
        "Finished epoch in {}s.".format(time_diff)
      )

      self.data_handler.save_to_log(
        "epoch: {}, train_acc: {}, train_loss: {}, valid_acc: {}, valid_los: {}, time: {}s\n"
        .format(
          (epoch+1),
          train_acc/n_batches,
          train_loss/n_batches,
          validation_acc,
          validation_loss,
          time_diff
        )
      )

      ###############################
      ###      EARLY STOPPING     ###
      ###############################

      # Save epoch with best validation loss for testing
      if validation_acc > best_acc:
        best_loss                 = validation_loss
        best_acc                  = validation_acc
        self.best_epoch           = (epoch+1)
        distance_from_improvement = 0

        # Save network parameters
        torch.save(
          self.model,
          self.get_tmp_model_path() + str(epoch+1) + '_f' + str(fold) + '.pt'
        )
      else:
        distance_from_improvement += 1

      if distance_from_improvement > self.patience:

        print_str = "***** No improvement in last {} epochs! "\
        "Stopping. Best epoch: {} => ACC: {}; LOSS: {};" \
        .format(
            self.patience,
            self.best_epoch,
            best_acc,
            best_loss,
        )
        self.logger.warning(print_str)
        self.data_handler.save_to_log(print_str + '\n')
        break

    return time_diff

  def _validate(self):

    validation_acc = 0
    validation_loss = 0
    validation_data = self.data_handler.get_validation_data()
    validation_set_size = len(validation_data)
    n_batches = np.ceil(validation_set_size/self.batch_size)

    np.random.shuffle(validation_data)

    self.logger.info(
      "[*] Running validation on {} samples.".format(
        validation_set_size,
      )
    )

    for idx in range(0, validation_set_size, self.batch_size):

      validation_X, validation_y = self.data_handler.load_sequence(
        validation_data[idx:idx+self.batch_size],
        length=self.max_len
      )

      X = torch.from_numpy(validation_X).float().cuda()
      y = torch.from_numpy(validation_y).long().cuda() # cross_entropy expect long for target

      self.model.eval()
      with torch.no_grad():
        torch.cuda.empty_cache()
        _y = self.model(X).cuda()

      # self.logger.info(
      #   "Data info --> validation: {} : {}".format(
      #     _y.shape,
      #     y.shape,
      #   )
      # )

      loss = F.cross_entropy(_y, y)
      _acc = ((torch.argmax(_y, dim=1)  == y).sum().item() / X.shape[0])

      validation_loss += loss.item()
      validation_acc  += _acc

    return validation_acc/n_batches, validation_loss/n_batches

  def _test(self, fold, model_path, test_data):

    self.logger.warning("*** Loading tensorflow Graph from {}.".format(model_path))

    result_file = self.data_handler.create_file(
      name="test_results_{}.txt".format(fold),
    )

    test_set_size = len(test_data)
    labels = []
    predictions = []
    scores = []

    self.model = torch.load(model_path)

    start_test_predict = time.time()

    self.model.eval()

    with torch.no_grad():
      torch.cuda.empty_cache()

      for idx in range(test_set_size):

        X, y = self.data_handler.load_sequence(
          [test_data[idx]],
          length=self.max_len
        )

        X = torch.from_numpy(X).float().cuda()

        # Call softmax to transform output into probabilities
        # https://discuss.pytorch.org/t/vgg-output-layer-no-softmax/9273/7
        probs = F.softmax(self.model(X), dim=1).float()
        _y    = torch.argmax(probs, axis=1).cpu().item()

        # Get score as 2D data
        scores.append(probs.detach().cpu().numpy()[0])

        labels.append(y[0])
        predictions.append(_y)

        result_file.write("{}, {}\n".format(y[0],
                                            _y))

      end_test_predict = time.time()

      n_classes = np.unique(labels).shape[0]

      acc   = metrics.accuracy_score(labels, predictions)
      f1    = metrics.f1_score(labels, predictions, average="weighted")
      if n_classes > 2:
        ytrue = label_binarize(labels, classes=[i for i in range(n_classes)]).ravel()
        probs = np.array(scores).ravel()
        probs = np.array(scores).ravel()
      else:
        ytrue = labels
        probs = np.array(scores)[:, 1]
      apc   = metrics.average_precision_score(ytrue, probs)

      difference = int(end_test_predict - start_test_predict)

      print_str = "\t\t *TEST* SET => Time: {}s; ACC: {:.4f}; F1: {:.4f}; APC:{:.4f}".format(difference, acc, f1, apc)

      self.logger.info(print_str)
      result_file.write(print_str)

      self.logger.info(f" Saving npz: metrics_test_results_{fold}.npz")
      np.savez(f"{self.data_handler.tmp_output_path}/metrics_test_results_{fold}.npz",
        y_true=labels,
        y=predictions,
        p=scores,
        acc=acc,
        f1=f1)

      self.logger.info("** Testing finished!")

    return acc, f1, difference

  def _test_injected(self, npz, fold, model_path, binarize=None):


    data = np.load(npz, mmap_mode='r', allow_pickle=True)

    total_samples = data['y'].shape[0]
    MBS=128

    self.logger.warning("*** Loading torch model from {}. Testing against {} samples.".format(model_path, total_samples))

    result_file_name = "{}_{}".format(npz.split('/')[-1].split('.')[0], fold)
    result_file = self.data_handler.create_file(
        name=f"test_results_{result_file_name}.txt",
    )

    labels = []
    predictions = []
    scores = []

    self.model = torch.load(model_path)

    start_test_predict = time.time()

    self.model.eval()

    with torch.no_grad():
      torch.cuda.empty_cache()

      # https://stackoverflow.com/questions/59216547/python-npzfile-objects-are-very-slow
      m_X = data['X']
      m_y = data['y']

      for idx in range(0, total_samples, MBS):

        batchX = m_X[idx:idx+MBS]
        batchY = m_y[idx:idx+MBS]
        size = batchX.shape[0]

        batch_data = list(zip(batchX, batchY))

        batch_X, _ = self.data_handler.load_sequence(
          batch_data,
          length=self.max_len,
          from_data=True
        )

        print(f"loaded {batch_X.shape}")

        for _id in range(size):

          if binarize is None:
            y = batchY[_id]
          else:
            sample_id = batchY[_id]
            sample_class_name = self.data_handler.id_map[sample_id]
            y = 1 if sample_class_name == binarize else 0

          X = torch.from_numpy(batch_X[_id]).float().cuda().reshape(1, -1)
          # y = batchY[_id]

          # Call softmax to transform output into probabilities
          # https://discuss.pytorch.org/t/vgg-output-layer-no-softmax/9273/7
          probs = F.softmax(self.model(X), dim=1).float()
          _y    = torch.argmax(probs, axis=1).cpu().item()

          # Get score as 2D data
          scores.append(probs.detach().cpu().numpy()[0])
          labels.append(int(y))
          predictions.append(_y)

          result_file.write("{}, {}\n".format(y,
                                              _y))

      end_test_predict = time.time()

      n_classes = np.unique(labels).shape[0]

      acc   = metrics.accuracy_score(labels, predictions)
      f1    = metrics.f1_score(labels, predictions, average="weighted")
      if n_classes > 2:
        ytrue = label_binarize(labels, classes=[i for i in range(n_classes)]).ravel()
        probs = np.array(scores).ravel()
      else:
        ytrue = np.array(labels)
        probs = np.array(scores)[:, 1]
      print(ytrue.shape, probs.shape)
      apc   = metrics.average_precision_score(ytrue, probs)
      # precision, recall, thresholds = metrics.precision_recall_curve(labels, scores)

      difference = int(end_test_predict - start_test_predict)

      print_str = "\t\t *TEST* SET (INJECTED) => Time: {}s; ACC: {:.4f}; F1: {:.4f}; APC: {:.4f}".format(difference, acc, f1, apc)

      self.logger.info(print_str)
      result_file.write(print_str)

      self.logger.info(f" Saving npz: {result_file_name}.npz")
      np.savez(f"{self.data_handler.tmp_output_path}/metrics_{result_file_name}.npz",
                y_true=labels,
                y=predictions,
                p=scores,
                acc=acc,
                f1=f1)

      self.logger.info("** Injection Testing finished!")

    return acc, f1, difference

  def test(self, path):
    self.logger.info("[*] Running in test only mode.")

    self.data_handler.split_dataset()
    self.n_classes = self.data_handler.n_classes
    self.data_handler.compute_fold_split()

    self.logger.info("** Fitting {} classes!".format(self.n_classes))

    self.model = self.create_model()

    self._test('test_only', path, self.data_handler.get_all_data())
